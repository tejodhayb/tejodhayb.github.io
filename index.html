<!DOCTYPE html>
<html lang="en">
<head>
  <title> Tejodhay Bonam - Portfolio </title>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="stylesheet" href="css/font-awesome.css">
  <link rel="stylesheet" href="css/style.css">
</head>
<body>

  <!--Page Loader Start-->
  <div class="page-loader">
    <div></div>
    <div></div>
    <div></div>
  </div>
  <!--Page Loader End-->

<!--Background Circles Start-->
<div class="bg-circles">
  <div class="circle-1">

  </div>
  <div class="circle-2">
    
  </div>
  <div class="circle-3">
    
  </div>
  <div class="circle-4">
    
  </div>

</div>
<!--Background Circles End-->

  <!--Overlay Start-->
<div class="overlay">
  
</div>
  <!--Overlay End-->
<!-- Main Start-->
  <div class="main hidden">


    <!--Header section start-->
     <header class="header">
       <div class="container">
         <div class="row flex-end">
           <button type="button" class="nav-toggler">
             <span></span>
            </button>
            <nav class="nav">
              <div class="nav-inner">
                <ul>
                  <li><a href="#home" class="nav-item link-item">Home</a></li>
                  <li><a href="#about" class="nav-item link-item">About</a></li>
                  <li><a href="#portfolio" class="nav-item link-item">Portfolio</a></li>
                  <li><a href="#contact" class="nav-item link-item">Contact</a></li>
                  
                </ul>
              </div>
            </nav>
         </div>
       </div>
     </header>
     <!--Header section end-->

    <!--Home section start-->
    <section class="home-section align-items-center" id="home">
      <div class="container">
        <div class="row align-items-center">
          <div class="home-text">
            <p>Hello, I'm</p>
            <h1>Tejodhay Bonam</h1>
            <h2>AS|EX Piring Data Scientist..</h2>
            <a href="#about" class="btn link-item">more about me</a>
            <a href="#portfolio" class="btn link-item">portfolio</a>
          </div>
          <div class="home-img">
           <div class="img-box">
             <img src="img/profile-img.png" alt="profile-img">
           </div>
        </div>
      </div>
    </div>
    </section>
    <!--Home Section End-->

    <!-- About Section Start-->
    <section class="about-section sec-padding" id="about">
      <div class="container">
        <div class="row">
          <div class="section-title">
            <h2>about me</h2>
          </div>
        </div>
        <div class="row">
          <div class="about-img">
            <div class="img-box">
              <img src="img/about-img.png" alt="about img">

            </div>
          </div>
          <div class="about-text">
            <p>Extract(or):
              I enjoy the process of gathering data and its engineering.<br>
              Transform(er):
Focusing on getting data ready, for its main showdown is my day job.<br>
Load(er):
I know how to write(to a DB as well).
            </p>
            <h3>skills</h3>
            <div class="skills">
              <div class="skill-item">Python</div>
              <div class="skill-item">SQL</div>
              <div class="skill-item">HTML5</div>
              <div class="skill-item">CSS3</div>
              <div class="skill-item">Data Wrangling (ETL Processes)</div>
              <div class="skill-item">Data Visualisation (Matplotlib, Seaborn)</div>
              <div class="skill-item">Computational and Data Preparation frameworks(Numpy, Pandas)</div>
              <div class="skill-item">Machine Learning Algorithms</div>
              <div class="skill-item">Deep Learning Algorithms</div>
              <div class="skill-item">DevOps( Git, AWS, Heroku)</div>
            </div>


            <div class="about-tabs">
              <button type="button" class="tab-item active" data-target="#education">education</button>
              <button type="button" class="tab-item" data-target="#experience">experience</button>
            </div>

            <!--Education Start-->
            <div class="tab-content active" id="education">
              <div class="timeline">
                <div class="timeline-item">
                  <span class="date">2018-2021</span>
                  <h4><b>Bachelor of Science(Honours) in Mathematics - <span>Sri Sathya Sai Institute of Higher Learning    (Bangalore, Karnataka)</b></span></h4>
                  <p>‚Ä¢ CGPA - 8.2/10 (O grade)<br>
                    ‚Ä¢ Among the top 5% across all Mathematics, Physics, Chemistry streams in Bachelors</p>
                </div>
                <div class="timeline-item">
                  <span class="date">2016-2018</span>
                  <h4><b>Intermediate, MPC - <span>Sri Chaitanya Jr. Kalasala    (Viveknagar, Kukatpally)</b></span></h4>
                  <p>‚Ä¢ Marks - 976/1000 <br>
                    ‚Ä¢ Ranked among top 0.1% among all the students who appeared for the Telangana State Board Exams<br>
                    ‚Ä¢ Scored 99 %ile on TS EAMCET<br>
                    ‚Ä¢ Scored 97.5 %ile in JEE MAINS 2018
                    </p>
                </div>
                <div class="timeline-item">
                  <span class="date">2015-2016</span>
                  <h4><b>Secondary School - <span>Narayana Concept School</b></span></h4>
                  <p>‚Ä¢ CGPA - 10/10 <br>
                    ‚Ä¢ Awarded All-round Excellence Award for the academic year 2015-16<br>
                    ‚Ä¢ Selected as House Captain( Hansraj) from among 25+ applicants
                  </p>
                </div>
              </div>

            </div>


            <!--Education end-->

            <!--Experience start-->
            <div class="tab-content" id="experience">
              <div class="timeline">
                <div class="timeline-item">
                  <span class="date">Jan 2021 - Present</span>
                  <h4><b>Arthashastra Intelligence Databases Pvt. Ltd. - <span>Data Science Intern</b><img src="img/portfolio/AI.gif"></span></h4>
                  <p>‚Ä¢ Worked on NLP projects for client on customer reviews where I developed trained and tested complicated
                    NLP algorithms such as BERT, GPT2 etc. for emotion and sentiment analysis.<br>
                    ‚Ä¢ Presented the analysis on open-source BI tool Apache Superset.<br>
                    ‚Ä¢ Performed client case studies on regression, clustering and classification.</p>
                </div>
                <div class="timeline-item">
                  <span class="date">Nov 2021 ‚Äì Dec 2021
                  </span>
                  <h4><b>Accenture Data Analytics - <span>Virtual Internship</b><img src="img/portfolio/accenture.gif"></span></h4>
                  <p>Completed practical task modules on<br>
                    ‚Ä¢ Project Understanding<br>
                    ‚Ä¢ Data Cleaning and Modeling<br>
                    ‚Ä¢ Data Visualization and Storytelling<br>
                    ‚Ä¢ Presenting to the Client</p>
                </div>
                <div class="timeline-item">
                  <span class="date"></span>
                  <h4><b><span></b></span></h4>
                  <p></p>
                </div>
              </div>

            </div>
             
            <!--Experience End-->

            <a href="cv.pdf" target="_blank" class="btn">download CV</a>
            <a href="#contact" class="btn link-item">contact me</a>
          </div>
        </div>
      
      </div>
    </section>
    <!--About Section End-->
     
  <!--Portfolio Section Start-->
    <section class="portfolio-section sec-padding" id="portfolio">
      <div class="container">
        <div class="row">
          <div class="section-title">
            <h2>recent projects</h2>
          </div>
        </div>
        <div class="row">

          <!--Portfolio item start-->
            <div class="portfolio-item">
              <div class="portfolio-item-thumbnail">
                <img src="img/portfolio/1.png" alt="portfolio item thumb">
              </div>
              <h3 class="portfolio-item-title">sow.reap.repeat.</h3>
              <button type="button" class="btn view-project-btn">view project</button>
              <div class="portfolio-item-details">
                <div class="description">
                  <p><b>SOW.REAP.REPEAT</b> üåø<br>
                    A simple ML and DL based website which recommends the best crop to grow, fertilizers to use and the diseases caught by your crops.<br></p>
                    <br>
                    <p><b>DISCLAIMER</b> ‚ö†Ô∏è<br>
                    This is a POC(Proof of concept) kind-of project. The data used here comes up with no guarantee from the creator. So, don't use it for making farming decisions. If you do so, the creator is not responsible for anything. However, this project presents the idea that how we can use ML/DL into precision farming if developed at large scale and with authentic and verified data.<br></p>
                    <br>
                    <b>MOTIVATION</b> üí™<br>
                    <li>Farming is one of the major sectors that influences a country‚Äôs economic growth.<br></li>
                    
                      <li>In country like India, majority of the population is dependent on agriculture for their livelihood. Many new technologies, such as Machine Learning and Deep Learning, are being implemented into agriculture so that it is easier for farmers to grow and maximize their yield.<br></li>
                    
                        <li>In this project, I present a website in which the following applications are implemented; Crop recommendation, Fertilizer recommendation and Plant disease prediction, respectively.<br></li>
                    <br>
                    <p>In the crop recommendation application, the user can provide the soil data from their side and the application will predict which crop should the user grow.<br></p>
                    <br>
                    <p>For the fertilizer recommendation application, the user can input the soil data and the type of crop they are growing, and the application will predict what the soil lacks or has excess of and will recommend improvements.<br></p>
                    <br>
                    <p>For the last application, that is the plant disease prediction application, the user can input an image of a diseased plant leaf, and the application will predict what disease it is and will also give a little background about the disease and suggestions to cure it.<br></p>
                    <br>
                    <b>DATA SOURCE</b> üìä<br>
                    <a href = "https://www.kaggle.com/atharvaingle/crop-recommendation-dataset" target="_blank">Crop recommendation dataset</a> (custom built dataset)<br>
                    <a href = "https://github.com/Gladiator07/Harvestify/blob/master/Data-processed/fertilizer.csv" target="_blank">Fertilizer suggestion dataset</a> (custom built dataset)<br>
                    <a href = "https://www.kaggle.com/vipoooool/new-plant-diseases-dataset" target="_blank">Disease detection dataset</a><br>
                    <br>
                    <b>Built with</b> üõ†Ô∏è<br>
                    <img src="img/portfolio/built.jpg"><br>
                    
                        
                    <br>
                    <b>DEPLOYMENT</b> üöÄ<br>
                    This website is deployed at Heroku<br>
                    You can access it here - <a href = "https://sow-reap-repeat.herokuapp.com/" target="_blank">sow.reap.repeat.</a><br>
                    Note: The website may take a minute to load sometimes, as the server may be in hibernate state<br>
                    <br>
                    <b>How to use</b> üíª<br>
                    <li>Crop Recommendation system ==> enter the corresponding nutrient values of your soil, state and city. Note that, the N-P-K (Nitrogen-Phosphorous-Pottasium) values to be entered should be the ratio between them. Refer <a href = "https://www.gardeningknowhow.com/garden-how-to/soil-fertilizers/fertilizer-numbers-npk.htm" target="_blank">this website</a> for more information. Note: When you enter the city name, make sure to enter mostly common city names. Remote cities/towns may not be available in the <a href = "https://openweathermap.org/" target="_blank">Weather API</a> from where humidity, temperature data is fetched.<br></li>
                    
                    <li>Fertilizer suggestion system ==> Enter the nutrient contents of your soil and the crop you want to grow. The algorithm will tell which nutrient the soil has excess of or lacks. Accordingly, it will give suggestions for buying fertilizers.<br></li>
                    
                    <li>Disease Detection System ==> Upload an image of leaf of your plant. The algorithm will tell the crop type and whether it is diseased or healthy. If it is diseased, it will tell you the cause of the disease and suggest you how to prevent/cure the disease accordingly. Note that, for now it only supports following crops<br></li>
                    <br>
                    Supported crops<br>
                    <li>Apple<br></li>
                    <li>Blueberry<br></li>
                      <li>Cherry<br></li>
                        <li>Corn<br></li>
                          <li>Grape<br></li>
                            <li>Pepper<br></li>
                              <li>Orange<br></li>
                                <li>Peach<br></li>
                                  <li>Potato<br></li>
                                    <li>Soybean<br></li>
                                      <li>Strawberry<br></li>
                                        <li>Tomato<br></li>
                                          <li>Squash<br></li>
                                            <li>Raspberry<br></li>
                    
                                            <br>                        
                                            <b>Usage</b> ‚öôÔ∏è<br>
                    You can use this project for further developing it and adding your work in it. If you use this project, kindly mention the original source of the project and mention the link of this repo in your report.<br>
                    <br>
                    <b>Further Improvements</b> üìà<br>
                    This was my first big project so there are lot of things to improve upon..<br>
                    <br>
                    <li>CSS code is totally messed up üòî (some code in file and some inline)<br></li>
                      <li>Frontend can be made more nicer (PS: I suck at frontend development) üò¢<br></li>
                        <li>More data can be collected manually via web scrapping to make the system more accurate üßê<br></li>
                          <li>Additional plant images can be collected to make the disease detection part more robust and generalized ü§ï<br></li>
                            <li>Modularized code can be written instead of writing in Jupyter Notebooks (will follow this in upcoming projects)</li></p>

                </div>
                <div class="general-info">
                  <ul>
                    <li>
                    Created - <span>4 Dec 2021</span>
                  </li>
                  <li>View Live - <span><a href="https://sow-reap-repeat.herokuapp.com" target="_blank">sow.reap.repeat.</a></span></li>
                  <li>View Github repository - <span><a href="https://github.com/TejodhayBonam/sow.reap.repeat" target="_blank">sow.reap.repeat.</a></span></li>
                  </ul>
                </div>
              </div>
            </div>
          <!--Portfolio item end-->

          <!--Portfolio item start-->
            <div class="portfolio-item">
              <div class="portfolio-item-thumbnail">
                <img src="img/portfolio/2.jpg" alt="portfolio item thumb">
              </div>
              <h3 class="portfolio-item-title">Movie Recommendation System</h3>
              <button type="button" class="btn view-project-btn">view project</button>
              <div class="portfolio-item-details">
                <div class="description">
                  <p><h2><b>Movie-Recommendation-System</b></h2><br>
                    ------------------------------------------------------------------------------<br>
                    <img src="img/portfolio/a.svg"> <img src="img/portfolio/b.svg"> <img src="img/portfolio/c.svg"> <img src="img/portfolio/d.svg"><br>
                    
                    This application provides all the details of the requested movie such as overview, genre, release date, rating, runtime, top cast, reviews, recommended movies, etc.<br>
                    <br>
                    The details of the movies(title, genre, runtime, rating, poster, etc) are fetched using an API by <a href="https://www.themoviedb.org/documentation/api" target="_blank">TMDB</a>, and using the IMDB id of the movie in the API, I did web scraping to get the reviews given by the user in the IMDB site using beautifulsoup4 and performed sentiment analysis on those reviews.<br>
                    <br>
                    <b>Link to the application</b><br>
                    Check out the live demo: <a href="https://movie-recommendation-system0.herokuapp.com/" target="_blank">Movie Recommendation System</a><br>
                    <br>
                    <b>Note</b><br>
                    Use this URL - <a href="https://movie-recommendation-system0.herokuapp.com/" target="_blank">https://movie-recommendation-system0.herokuapp.com/</a> - in case if you see application error in the above mentioned URL<br>
                    <br>
                    Don't worry if the movie that you are looking for is not auto-suggested. Just type the movie name and click on "enter". You will be good to go even though if you made some typo errors.<br>
                    <br>
                    <b>How to get the API key?</b><br>
                    Create an account in <a href="https://www.themoviedb.org/" target="_blank">https://www.themoviedb.org/</a>, click on the API link from the left hand sidebar in your account settings and fill all the details to apply for API key. If you are asked for the website URL, just give "NA" if you don't have one. You will see the API key in your API sidebar once your request is approved.<br>
                    <br>
                    <b>How to run the project?</b><br>
                    <ol>1. Clone this repository in your local system.<br></ol>
                    <ol>2. Install all the libraries mentioned in the requirements.txt file with the command pip install -r requirements.txt.<br></ol>
                      <ol>3. Replace YOUR_API_KEY in both the places (line no. 23 and 43) of static/recommend.js file.<br></ol>
                        <ol>4. Open your terminal/command prompt from your project directory and run the main.py file by executing the command python main.py.<br></ol>
                          <ol>5. Go to your browser and type http://127.0.0.1:5000/ in the address bar.<br></ol>
                    <ol>6. Hurray! That's it.<br></ol>
                    <br>
                    <b>Sources of the datasets</b><br>
                    <ol>1. <a href="https://www.kaggle.com/carolzhangdc/imdb-5000-movie-dataset" target="_blank">IMDB 5000 Movie Dataset</a><br></ol>
                      <ol>2. <a href="https://www.kaggle.com/rounakbanik/the-movies-dataset" target="_blank">The Movies Dataset</a><br></ol>
                        <ol>3. <a href="https://en.wikipedia.org/wiki/List_of_American_films_of_2018" target="_blank">List of movies in 2018</a><br</ol>
                          <ol>4. <a href="https://en.wikipedia.org/wiki/List_of_American_films_of_2019" target="_blank">List of movies in 2019</a><br></ol>
                            <ol>5. <a href="https://en.wikipedia.org/wiki/List_of_American_films_of_2020" target="_blank">List of movies in 2020</a></p></ol>

                </div>
                <div class="general-info">
                  <ul>
                    <li>
                    Created - <span>8 Dec 2021</span>
                  </li>
                  <li>technologies used - <span>Python|3.8, Framework|Flask, Frontend|HTML/CSS/JS, API|TMDB</span></li>
                  <li>View Live - <span><a href="https://movie-recommendation-system0.herokuapp.com/" target="_blank">movie recommendation system</a></span></li>
                  <li>View Github repository - <span><a href="https://github.com/TejodhayBonam/Movie_Recommendation_System" target="_blank">Movie_Recommendation_System</a></span></li>
                  </ul>
                </div>
              </div>
            </div>
          <!--Portfolio item end-->

          <!--Portfolio item start-->
      <div class="portfolio-item">
        <div class="portfolio-item-thumbnail">
          <img src="img/portfolio/face_front.png" alt="portfolio item thumb">
        </div>
        <h3 class="portfolio-item-title">Face Frontalization using Generative Adversarial Networks</h3>
        <button type="button" class="btn view-project-btn">view project</button>
        <div class="portfolio-item-details">
          <div class="description">
            <p><b><h2 id="Generative-adversarial-Networks-Face-profile-completion">Generative-adversarial-Networks-Face-profile-completion</h2></b><br>
              Based on the idea of expediting the process of catching criminals using Neural Networks. This project pertains to using Deep learning model like adverserial networks(2 CNN neural networks) compete against each other , One to generate fake images(generator) , other to defy it(discriminator).<br>
              <br>
              <h3>Objective: Given the profile of a person , can we generate the entire face structure.</h3><br>
              <li>Infrastructure: Figure out how to set up Google Cloud ML instance utilising the $300 credits.<br></li>
              <br>
              <li>Code : Segmented into <br>2.1) Data.py ( How to get data onto the GCP platform ) <br>2.2) Network.py ( Setting up the CNN's for generation and discrimination ) <br>2.3) Main.py ( Running 500 epochs and taking the model evaluation paramater as L1, L2 and Binary cross entropy(as our results are binary in nature) <br>2.4) test.py ( To test our model over the test images )<br></li>
              <br>
              <li>Dataset: Getting facial datasets with side and frontal (training data obtained from CMU Multi-pie Face Dataset) <br>3.1) Manual pre-processing of images to required dimensions <br>3.2) Tagging (pairing) of side and frontal as training set<br></li>
              <br>
              Check the 499_real, 499_input , 499_generated in the Github repository for the accuracy achieved.<br>
              <br>
              <h3>A bit of Theory for the concept:</h3><br>
              There are two main concepts that we will need for the face Frontalization:<br>
              <br>
              1. The Encoder/Decoder Network<br>
              2. The Generative Adversarial Network<br><br>
              Encoders and Decoders<br>
              <br>
              <b>THE ENCODER</b><br>
              <br>
              The network takes images that are sized 128 by 128 as input. Since the images are in colour (meaning 3 colour channels for each pixel), this results in the input being 3 √ó 128 √ó 128 = 49152 dimensional. We can get away with a mere 512 dimensional vector (which is simply another way of saying ‚Äú512 numbers‚Äù) to encode all the information that we care about. This is an example of dimensionality reduction: the Encoder network learns a lower dimensional representation of the input.<br>
              <br>
              Here we start with input that is 128√ó128 and has 3 channels. As we pass it through convolutional layers, the size of the input gets smaller and smaller (from 128√ó128 to 64√ó64 to 16√ó16 etc on the figure above) whereas the number of channels grows (from 3 to 8 to 16 and so on). This reflects the fact that the deeper the convolutional layer, the more abstract are the features that it learns. In the end we get to a layer whose output is sized 1√ó1, yet has a very high number of channels: 256 in the example depicted above (or 512 in our own network). 256√ó1 and 1√ó256 are really the same thing, if you think about it, so another way to put it is that the output of the Encoder is 256 dimensional (with a single channel), so we have reduced the dimensionality of the original input from 49152 to 256. Having this lower dimensional representation helps us prevent overfitting our final model to the training set.<br>
              <br>
              <b>THE DECODER</b><br>
              <br>
              As the name suggests, the Decoder‚Äôs job is the inverse of that of the Encoder. In other words, it takes the low-dimensional representation output of the Encoder and has it go through deconvolutional layers (also known as the transposed convolutional layers). The architecture of the Decoder network is often symmetric to that of the Encoder, although this does not have to be the case. The Encoder and the Decoder are often combined into a single network.<br>
              <br>
              In this project this Encoder/Decoder network is called the Generator. The Generator takes in a profile image, and (if we do our job right) outputs a frontal one.</p>

          </div>
          <div class="general-info">
            <ul>
              <li>
              Created - <span>8 Dec 2021</span>
            </li>
            <li>technologies used - <span>Neural Networks, Deep Learning</span></li>
            <li>View Github repository - <span><a href="https://github.com/TejodhayBonam/Generative-adversarial-Networks-Face-profile-completion" target="_blank">Generative-adversarial-Networks-Face-profile-completion</a></span></li>
            </ul>
          </div>
        </div>
      </div>
    <!--Portfolio item end-->


          <!--Portfolio item start-->
            <div class="portfolio-item">
              <div class="portfolio-item-thumbnail">
                <img src="img/portfolio/music-genres-1024x768.jpg" alt="portfolio item thumb">
              </div>
              <h3 class="portfolio-item-title">Music Genre Classification using Lyrics</h3>
              <button type="button" class="btn view-project-btn">view project</button>
              <div class="portfolio-item-details">
                <div class="description">
                  <p><h3><b>Music-Genre-Classification-using-Lyrics</b></h3><br>
                    <img src="img/portfolio/music.jpg"> <img src="img/portfolio/music_classification.jpeg" width="70%" height="40%"><br>
                    <br>
                    <b>Abstract</b><br>
                    <br>
                    This project aims to build a system that can identify the genre of a song based on its lyrics. We identify a set of features that establish the style of a particular song. We curate a set of songs with ve labels - Rock, Hip-Hop, Jazz, Country and Pop. Then we design three models to classify the songs into their genres - Multi Layer Perceptron for multiclass classification, Random Forest for binary classification and Convolutional Neural Networks with word embeddings. We provide a user interface which would enable a user to input the lyrics of a particular song and our program would predict its genre based on the content of the lyrics.<br>
                    <br>  
                    <b>Introduction</b><br>
                    <br>
                    In the field of Natural Language Processing, the classification of genres of a song solely based on the lyrics is considered a challenging task. Because audio features of a song also provides valuable information to classify the song into its respective genre. Previously researchers have tried several approaches to this problem, but they have failed to identify a method which would perform significantly well in this case. SVM, KNN and Naive Bayes have been used previously in lyrical classification research. But, classification into more than 10 genres have not been particularly successful, because then the clear boundary between the genres is often lost. So, we try to use a dataset of five genres. Hence, we try to approach this problem as a supervised learning problem applying several methods. We analysed the relative advantages and disadvantages of each of the methods and finally reported our observations. With the advent of deep learning, it has been observed that Neural Networks perform better than the previously used models. So we designed a Convoluted Neural Network using glove word embeddings and analysed its performance.<br>
                    <br>
                    <b>Dataset</b><br>
                    <br>
                    The dataset for this problem was not abundant mostly due to copyright issues. However, after comparing datasets from several sources, we found out a data set in Kaggle which was most suited for our purpose. The dataset is basically a collection of 380000+ lyrics from songs scraped from metrolyrics.com.The structure of the data is index/song/year/artist/genre/lyrics. The data was not properly structured according to our needs like there were some songs without any genre classified to it or there were some songs whose lyrics were absent. Sowe had to process our data before it could be fitted to any model for classification. Initially, we had to remove some irrelevant data from our dataset, making it more compact and easy to access. Like we removed artist and song year information thus creating just lyrics and genre mapping in our dataset. Then we extracted songs of five genres - Rock, Hip-Hop, Pop, Country, Jazz. And extracted 5000 songs from each genre, making the dataset practical and easy to analyze. Then we removed some songs which had very few words in its lyrics. Lyrics also contained some rhyming schemes like [chorus], [verse], [x1],[x2], we removed them for simplicity. Then we tokenized the lyrics text using NLTK tool in Python. Further, we applied stemming and removed punctuations. For stemming we used Porter Stemmer as we found it to be very effective. We also did some pre-processing of data for each of our models, which would be explained later.<br>
                    <br>
                    <b>Data Analysis</b><br>
                    <br>
                    After preprocessing we analysed the data and identified the features of data which is the first step of any machine learning problem. We used Spark to analyse the data and visualized the data. This analysis helped us understand the features of the data that would be most useful for the task in our hand. We evaluated the average length of lyrics in each genre, and we had an interesting insight, Hip-Hop songs were longer as compared to the other genres. And the rest of the genres had almost similar lengths. Then we calculated the average number of unique words in each genre. (Figure 1) Here as well we found out that Hip-Hop songs had more unique words as compared to the rest. Then we calculated the most common words of each genre. (Figure 2) This would help us understand any correlation between the words used in lyrics and the genre type.<br>
                    <br>
                    <img src="img/portfolio/data_analysis.png"><br>
                    <br>
                    <b>Approaches</b><br>
                    <br>
                    We have taken three approaches to the problem, resulting in three models. In our first approach we use term frequency and inverse document frequency as our feature vectors and the genre classes as our labels to identify. We developed Naive Bayes, Random Forest, Support Vector machine and Multi Layer Perceptron model to classify the songs into multiple classes. In the second model we convert the problem into a binary classication problem and developed a classifier which will identify a song as Rock or Non Rock, Hip-Hop or Non Hip-Hop. We did this to identify the genres which are more distinguishable from the rest on the basis of the content of its songs. The third model that we used was the most effective of all, we used a Convolutional Neural Network, with Glove word embeddings as the feature vector.<br>
                    <br>
                    <b>Model I</b><br>
                    
                    We used term frequency and inverse document frequency as our feature vectors and the genre classes as our labels to identify.<br>
                    <br>
                    <b>Bag of Words</b><br>
                    <br>
                    This is one of the most common approaches in text retrieval. Here, any unique term occurring in any of the document of the collection is regarded as a feature. One simple approach is to count the frequency of the word in the entire lyrical text. Another approach is term weighting scheme based on the importance of a term to describe and discriminate between documents, such as the popular tf - idf (term frequency times inverse document frequency) weighting scheme. In this model, a document is denoted by d, a term (token) by t, and the number of documents in a corpus by N. The term frequency tf(t, d) denotes the number of times term t appears in document d. The number of documents in the collection that term t occurs in is denoted as document frequency df(d). The tf-idf weight of a term in a document is computed as:<br>
                    <br>
                    tf x idf(t, d) = tf (t, d) x ln(N/df(t))<br>
                    We have also normalized the vector after applying the Count Vectorizer and Tf-Idf Weighing scheme.<br>
                    <br>
                    <b>Word2Vec</b><br>
                    Next, we used the word vectors (word2vec) to represent our lyrical text. These semantic vectors preserve most of the relevant information in a text while having relatively low dimensionality. Word2Vec is an algorithm that takes every word in your vocabulary that is, the text that needs to be classied is turned into a unique vector that can be added, subtracted, and manipulated in other ways just like a vector in space. We trained word vectors using python's genism library. We generated 100-dimensional word2vec embedding trained on the benchmark data itself.<br>
                    <br>
                    <b>Algorithms</b><br>
                    <br>
                    With our features and labels ready we fed them into a classier and trained it. We used 4:1 split of the dataset for training and testing. We used python's sci-kit learn library to implement the following algorithms:<br>
                    <br>
                    Naive Bayes: Implemented Bernoulli and Multinomial Naive Bayes, Support Vector Machine: Used the linear kernel, Logistic Regression, Decision Tree, Random Forest: Used 100 trees and the majority of all the classifications are the result, MultiLayer Perceptron Model: Experimented with various activation functions and hidden layers, Extra Trees Classifier: Used this algorithm to test with word2vec feature vectors, Extra Trees Classier: Used this algorithm to test with word2vec feature vectors.<br>
                    <br>
                    <b>Model II</b><br>
                    
                    We converted the problem into a binary classification problem and developed a classifier which will identify a song as Rock or Non Rock, Hip-Hop or Non Hip-Hop. We did this to identify the genres which are more distinguishable from the rest on the basis of the content of its songs.<br>
                    <br>
                    <b>Features</b><br>
                    <br>
                    We divided the data into two groups for each of the genre classes, like grouping dataset into rock and non-rock, hip- hop and non hip-hop etc. We used one hot encoding to represent the class labels and used term frequency-inverse document frequency to represent the features. We implemented this model to identify the genres which were easily classified as compared to the rest.<br>
                    <br>
                    <b>Model III</b><br>
                    
                    We used a Convolutional Neural Network to classify the songs into their respective genres. We used pre-trained glove vectors for this model.<br>
                    <br>
                    <b>Description of the model</b><br>
                    The glove model we used is Google Glove 6B vector 100d. We have implemented two CNN models using Keras library: i. Simple convolution model: We have implemented a single layer of convoluted and maxpool layer. ii. Dense convolution model: We have implemented multiple convoluted and maxpool layers with filter sizes of 3, 4 and 5.(Figure 3)<br>
                    <br>
                    <img src="img/portfolio/description.png"><br>
                    <br>
                    <b>User Interface</b><br>
                    <br>
                    After training our models, we designed an user interface, when a user can enter the lyrics of a song and our program would predict the genre of the song.<br>
                    <br>
                    <img src="img/portfolio/user_interface.png"><br>
                    <br>
                    <b>Results</b><br>
                    <br>
                    Now we report the results of experiments on these models on a dataset of 25000 songs equally distributed among all the genres.<br>
                    <br>
                    <b>Model I</b><br>
                    A summarization of the results is demonstrated in the figure. We tested for with both TF-IDF vectors and counts as our feature vectors. We observe that TF-IDF vectors are better representation of the words in the lyrics. And among the algorithms, Multi Layer Perceptron performed better than the other algorithms with an overall accuracy of 63.5% accuracy. SVM comes close second with 61.9% accuracy. The confusion matrix shows that Hip-Hop is most accurately classified and Jazz is mislabeled most of the times. Then, we used word2vec as our feature vector, and applied the Extra Trees Classifier and Support Vector Machines, and we observed accuracy of 60.3% and 62.4%. Hence the use of word2vec did not produce significant improvement in our problem.<br>
                    <br>
                    <img src="img/portfolio/model1.png"><br>
                    <br>
                    <img src="img/portfolio/model1_.png"><br>
                    <br>
                    <img src="img/portfolio/model1__.png"><br>
                    <br>
                    <b>Model II</b><br>
                    The results of binary classification were better, which helped us in analysing the problem in even more detail. We identified that using the words in the lyrics, Hip Hop genre was most accurately labeled as compared to the rest of the genres.<br>
                    <br>
                    <img src="img/portfolio/model2.png"><br>
                    <br>
                    <b>Model III</b><br>
                    We ran the model multiple number of times, changing the following parameters:<br>
                    <br>
                    <li>learning rate: Modified the learning rate from 1 to 10-7<br></li>
                      <li>adjusting the dropout: Adjusted the dropout layers and modified its values<br></li>
                        <li>modifying the filter sizes: Used filters of sizes 3,4 and 5<br></li>
                          <li>Increasing the number of epochs: Providing enough time for the model to learn<br></li>
                            <li>Increasing batch size: Tried batch sizes of 32,64 and 128<br></li>
                            <br>
                    In the simple convolutional neural network we could achieve an accuracy of 69.2% and in the dense model we could achieve an accuracy of 71%. Both were run for over a hundred epochs. This is a significant development as compared to the previous two models.<br>
                    <br>
                    <img src="img/portfolio/model3.png"><br>
                    <br>
                    <b>Conclusions and Future Work</b><br>
                    <br>
                    From the models that we developed and the experiments that we conducted we can say that the Convolutional Neural Network Model performed significantly well compared to the other models. However, the training time for an CNN is very high even though pre-trained word embeddings were used as feature vectors. In that respect Multi Layer Perceptron, SVM and Random Forest perform well. Apart from Hip-Hop (as seen from the confusion matrix) other genres might be mislabeled at times. Accordingly, the user interface works quite well for hip-hop genre lyrics. However limited by time, we could produce some significant results in the field of music genre classification based on lyrics. There is a lot that can be done like better pre-processing of data. Adding more data for each of genre classes. We might train a model with lyrics as well as audio features and it is expected that we can get better results. Also, we might train a more complex model which would remember order of words like an LSTM, and we can experiment on our training data. Classification by lyrics will always be inherently awed by vague genre boundaries with many genres borrowing lyrics and styles from one another. For example one merely need consider cover songs which utilise the same lyrics but produce songs in vastly different genres, songs which have no lyrical content. To produce a state of the art classifier is is evident that this classifier must take into account more than just the lyrical content of the song. Audio data typically performs the strongest and further research could look into employing these models to the audio and symbolic data and combining with the lyrics to build a stronger classifier.</p>

                </div>
                <div class="general-info">
                  <ul>
                    <li>
                    Created - <span>20 Dec 2021</span>
                  </li>
                  <li>View Github repository - <span><a href="https://github.com/TejodhayBonam/Music-Genre-Classification-using-lyrics" target="_blank">Music-Genre-Classification-using-lyrics</a></span></li>
                  </ul>
                </div>
              </div>
            </div>
          <!--Portfolio item end-->

          <!--Portfolio item start-->
          <div class="portfolio-item">
            <div class="portfolio-item-thumbnail">
              <img src="img/portfolio/4.png" alt="portfolio item thumb">
            </div>
            <h3 class="portfolio-item-title">Flight Fare Prediction</h3>
            <button type="button" class="btn view-project-btn">view project</button>
            <div class="portfolio-item-details">
              <div class="description">
                <p><h1 id="flight-fare-prediction-">Flight Fare Prediction:</h1>
                  <h2 id="table-of-content">Table of Content</h2>
                  
                  <li>Demo</li>
                  <li>Overview</li>
                  <li>Motivation</li>
                  <li>Installation</li>
                  <li>Deployement on Heroku</li>
                  <li>Directory Tree</li>
                  <li>Future scope of project</a></li>
                  
                  <h2 id="demo">Demo</h2><br>
                  <p><img src="img/portfolio/4.png" alt=""></p><br>
                  <p><img src="img/portfolio/flight.png" alt=""></p><br>
                  <h2 id="overview">Overview</h2>
                  <p>This is a Flask web app which predicts fare of Flight ticket.</p>
                  <h2 id="motivation">Motivation</h2>
                  <p>What to do when you are at home due to this pandemic situation? I started to learn Machine Learning model to get most out of it. I came to know mathematics behind all supervised models. Finally it is important to work on application (real world application) to actually make a difference.</p>
                  <h2 id="installation">Installation</h2>
                  <p>The Code is written in Python 3.6.10. If you don&#39;t have Python installed you can find it <a href="https://www.python.org/downloads/">here</a>. If you are using a lower version of Python you can upgrade using the pip package, ensuring you have the latest version of pip. To install the required packages and libraries, run this command in the project directory after <a href="https://www.howtogeek.com/451360/how-to-clone-a-github-repository/">cloning</a> the repository:</p>
                  <pre><code class="lang-bash">pip <span class="hljs-keyword">install</span> -r requirements.txt
                  </code></pre>
                  <h2 id="deployement-on-heroku">Deployement on Heroku</h2>
                  <p>Login or signup in order to create virtual app. You can either connect your github profile or download ctl to manually deploy this project.</p>
                  <p><a href="https://heroku.com"><img src="https://i.imgur.com/dKmlpqX.png" alt=""></a></p>
                  <p>Our next step would be to follow the instruction given on <a href="https://devcenter.heroku.com/articles/getting-started-with-python">Heroku Documentation</a> to deploy a web app.</p>
                  <h2 id="directory-tree">Directory Tree</h2>
                  <pre><code>‚îú‚îÄ‚îÄ static 
                  ‚îÇ   ‚îú‚îÄ‚îÄ css
                  ‚îú‚îÄ‚îÄ template
                  ‚îÇ   ‚îú‚îÄ‚îÄ home<span class="hljs-selector-class">.html</span>
                  ‚îú‚îÄ‚îÄ Procfile
                  ‚îú‚îÄ‚îÄ README<span class="hljs-selector-class">.md</span>
                  ‚îú‚îÄ‚îÄ app<span class="hljs-selector-class">.py</span>
                  ‚îú‚îÄ‚îÄ flight_price<span class="hljs-selector-class">.ipynb</span>
                  ‚îú‚îÄ‚îÄ flight_rf<span class="hljs-selector-class">.pkl</span>
                  ‚îú‚îÄ‚îÄ requirements.txt
                  </code></pre><h2 id="technologies-used">Technologies Used</h2>
                  <p><img src="https://forthebadge.com/images/badges/made-with-python.svg" alt=""></p>
                  <p><a href="https://flask.palletsprojects.com/en/1.1.x/"><img target="_blank" src="https://flask.palletsprojects.com/en/1.1.x/_images/flask-logo.png" width=170></a> <a href="https://gunicorn.org"><img target="_blank" src="https://number1.co.za/wp-content/uploads/2017/10/gunicorn_logo-300x85.png" width=280></a> <a href="https://scikit-learn.org/stable/"><img target="_blank" src="https://scikit-learn.org/stable/_static/scikit-learn-logo-small.png" width=200></a> </p>
                  
                  <h2 id="future-scope">Future Scope</h2>
                  
                  <li>Use multiple Algorithms</li>
                  <li>Optimize Flask app.py</li>
                  <li>Front-End </li>
                  
                  </p>
              </div>
              <div class="general-info">
                <ul>
                  <li>
                  Created - <span>8 Dec 2021</span>
                </li>
                
                <li>View Github repository - <span><a href="https://github.com/TejodhayBonam/Flight-Fare-Prediction" target="_blank">Flight-Fare-Prediction</a></span></li>
                </ul>
              </div>
            </div>
          </div>
        <!--Portfolio item end-->

        <!--Portfolio item start-->
        <div class="portfolio-item">
          <div class="portfolio-item-thumbnail">
            <img src="img/portfolio/3.jpg" alt="portfolio item thumb">
          </div>
          <h3 class="portfolio-item-title">Sports Celebrity Classification</h3>
          <button type="button" class="btn view-project-btn">view project</button>
          <div class="portfolio-item-details">
            <div class="description">
              <p>In this data science and machine learning project, we classify sports personalities. We restrict classification to only 5 people,<br>
                <br>
                1. Maria Sharapova<br>
                2. Serena Williams<br>
                3. Virat Kohli<br>
                4. Roger Federer<br>
                5. Lionel Messi<br>
                <br>
                Here is the folder structure,<br>
                <br>
                <li>UI : This contains ui website code<br></li>
                  <li>server: Python flask server<br></li>
                    <li>model: Contains python notebook for model building<br></li>
                      <li>google_image_scrapping: code to scrap google for images<br></li>
                        <li>images_dataset: Dataset used for our model training<br></li>
                        <br>
                Technologies used in this project,<br>
                <br>
                1. Python<br>
                2. Numpy and OpenCV for data cleaning<br>
                3. Matplotlib & Seaborn for data visualization<br>
                4. Sklearn for model building<br>
                5. Jupyter notebook, visual studio code and pycharm as IDE<br>
                6. Python flask for http server<br>
                7. HTML/CSS/Javascript for UI</p>

            </div>
            <div class="general-info">
              <ul>
                <li>
                Created - <span>8 Dec 2021</span>
                </li>
              <li>View Github repository - <span><a href="https://github.com/TejodhayBonam/Celebrity-Image-Classification" target="_blank">Celebrity-Image-Classification</a></span></li>
              </ul>
            </div>
          </div>
        </div>
          <!--Portfolio item end-->

         <!--Portfolio item start-->
        <div class="portfolio-item">
          <div class="portfolio-item-thumbnail">
            <img src="img/portfolio/chatbot.png" alt="portfolio item thumb">
          </div>
          <h3 class="portfolio-item-title">Same Old Chat bot</h3>
          <button type="button" class="btn view-project-btn">view project</button>
          <div class="portfolio-item-details">
            <div class="description">
              <p><b>Build your Chatbot to get your favourite cricket match scores</b><br>
                <br>
                Nah, its not the same old chat bot. Its all about implementing RASA stack which is a framework mainly used for NLP/NLU purposes. We ll be making a chatbot that you can deploy on slack as well so that you can fetch match scores at the tip of your hand(oh sorry your keyboard). Follow the below steps for the entire project building.<br>
                <br>
                <b>SETUP</b><br>
                <br>
                If you haven‚Äôt installed Rasa NLU and Rasa Core yet, you can do it by navigating to the project directory and running:<br>
                pip install -r requirements.txt<br>
                You also need to install a spaCy English language model. You can install it by running:<br>
                python -m spacy download en<br>
                <br>
                <b>Rasa NLU model files</b><br>
                <br>
                <li>data/nlu_data.md file contents training data for the NLU model.<br></li>
                <li>nlu_config.yml Config for RASA NLU pipeline<br></li>
                <br>
                language: "en"<br>
                pipeline: spacy_sklearn<br>
                <br>
                <b>Files for Rasa Core model</b><br>
                <br>
                <li>data/stories.md training stories which represent the conversations between a user and the assistant.<br></li>
                  <li>domain.yml file describes the domain of the assistant which includes intents, entities, slots, templates and actions for the assistant to understand.<br></li>
                    <li>actions.py file contains the code of a custom action which retrieves results of the latest IPL match by making an external API call.<br></li>
                      <li>endpoints.yml file contains the webhook configuration for custom action.<br></li>
                        <li>policies.yml file contains the configuration of the training policies for Rasa Core model.<br></li>
                <br>
                <b>HOW TO RUN LOCALLY:</b><br>
                <br>
                Note: If running on Windows, you will either have to <a href="http://gnuwin32.sourceforge.net/packages/make.htm" target="_blank">install make</a> or copy the following commands from the <a href="https://github.com/RasaHQ/starter-pack-rasa-stack/blob/master/Makefile" target="_blank">Makefile</a><br>
                <br>
                1. You can train the Rasa NLU model by running:<br>
                make train-nlu<br>
                This will train the Rasa NLU model and store it inside the /models/current/nlu folder of your project directory.<br>
                <br>
                2. Train the Rasa Core model by running:<br>
                make train-core<br>
                This will train the Rasa Core model and store it inside the /models/current/dialogue folder of your project directory.<br>
                <br>
                3. In a new terminal start the server for the custom action by running:<br>
                make action-server<br>
                This will start the server for emulating the custom action.<br>
                <br>
                4. Test the assistant by running:<br>
                make cmdline<br>
                This will load the assistant in your terminal for you to chat.<br>
                <br>
                <b>HOW TO DEPLOY THE SLACK:</b><br>
                <br>
                1. Go to your Slack app's settings page and use the Bot User OAuth Access Token:<br>
                And add this in the slack_credentials.yml file:<br>
                slack:<br>
                  slack_token: "Bot User OAuth Access Token"<br>
                  slack_channel: <br>
                  <br>
                2. Start the action server by typing the following command in terminal:<br>
                make action-server<br>
                <br>
                3. Setup ngrok for the port that the action server is using by the following command:<br>
                ngrok http 5055<br>
                <br>
                4. Copy the highlighted url in the above image into your endpoints.yml file:<br>
                action_endpoint: "your_url_here/webhook"<br>
                  url: <br>
                  <br>
                5. Start the core server in another terminal window:<br>
                python -m rasa_core.run -d models/current/dialogue -u models/current/nlu --port 5002 --connector slack --credentials slack_credentials.yml --endpoints endpoints.yml<br>
                This will start the server at port 5002.<br>
                <br>
                6. Now you have to expose this port to the world by using ngrok, open another terminal and type:<br>
                ngrok http 5002<br>
                <br>
                7. Take the above url and paste it into the Events Subscription page of your slack app in the following format:<br>
                your_url_here/webhooks/slack/webhook</p>

            </div>
            <div class="general-info">
              <ul>
                <li>
                Created - <span>22 Dec 2021</span>
              </li>
              <li>View Github repository - <span><a href="https://github.com/TejodhayBonam/SameOldChatBot" target="_blank">SameOldChatBot</a></span></li>
              </ul>
            </div>
          </div>
        </div>
      <!--Portfolio item end-->

    
      <!--Portfolio item start-->
      <div class="portfolio-item">
        <div class="portfolio-item-thumbnail">
          <img src="img/portfolio/self-driving-cars.webp" alt="portfolio item thumb">
        </div>
        <h3 class="portfolio-item-title">Self Driving Car</h3>
        <button type="button" class="btn view-project-btn">view project</button>
        <div class="portfolio-item-details">
          <div class="description">
            <p><h1 id="selfdrivingcar">SelfDrivingCar</h1>
              <h2 id="running-the-simulation-">Running the simulation:</h2>
              <p><code>python SearchAgent.py &lt;config_file_name&gt;</code>
              For example python SearchAgent.py dynamic_config1.txt</p>
              <br>
              <p>On the gui your car is the white color car.</p>
              <h4 id="there-are-5-example-config-files-provided-for-your-testing-">There are 5 example config files provided for your testing.</h4>
              <h4 id="dynamic_config-number-txt-is-the-config-file-which-contains-the-starting-location-of-your-car-and-the-number-and-the-starting-location-of-other-cars-on-the-road-your-assignment-will-be-evaluated-against-a-different-set-of-config-files-">dynamic_config<number>.txt is the config file which contains the starting location of your car and the number and the starting location of other cars on the road. Your assignment will be evaluated against a different set of config files.</h4>
              <p>====================================================================================<br>
              We describe the simulator in which you have to write the code. There are 5 files provided.</p><br>
              <ol>
              <li>Simulator.py -contains the code for the gui. </li>
              <li>Environment.py ‚Äì contains the code for environment and movement of other cars.</li>
              <li>searchUtils.py ‚Äì contains utility functions for search algorithms. You may use these utility functions. You can add/modify these utility functions as per your requirement.</li>
              <li>randomagent.py ‚Äì contains the example code for a car which takes a random action at each timestep.</li>
              <li>SearchAgent.py ‚Äì contains the basic code for your car. </li>
              </ol>
              <br>
              <p>Function in the SearchAgent.py which returns the sequence of actions to be taken by the car. This function is called at each step.<br>
              The drive function takes as input the python list of a goal states (with only one element) and the inputs sensed from the environment. On calling env.sense it returns the status of the grid as seen by the car. 0 if the cell is clear, 1 if there is any other car present and -1 if the information is not known to your self driving car (i.e. the cell is not in the visibility range of the car).</p><br>
              
              <p>As an example, the drive function can implement A* search from the car‚Äôs current location to the goal state and stores the action sequence.<br>
              The update function in SearchAgent class is called at each timestep. Your algorithm should choose the action in the update function based on the action sequence generated using the drive function.<br>
              The intended action is conveyed to the environment using act function which returns the updated state of the car and also updates the state in the environment.<br>
              Environment first updates the position of your car before updating the position of any other car.</p><br>
              <br>
              <h3 id="following-are-the-class-variables-for-the-agent-class-">Following are the class variables for the agent class:</h3><br>
              <p>valid_actions ‚Äì list of valid actions available for your car.<br>
              Env ‚Äì Instance of the environment class.<br>
              Searchutil ‚Äì Instance of the searchUtils class<br>
              state ‚Äì dictionary representing state of your car. State[‚Äúlocation‚Äù] ‚Äì provides the location of your car in grid cell. For eg. If state[‚Äúlocation‚Äù] = (2,3) it means that car is located in the cell 2,3.<br>
              <br>Following are the functions which you can use to write the algorithm for self driving car to choose an action at each timestep.</p><br>
              <p>Environment class functions ‚Äì can be accessed by calling self.env.<functionname></p><br>
              <ol>
              <li>getGoalStates() ‚Äì returns the list of goal states.</li>
              <li>act(car,a) ‚Äì takes action a for the car and returns the new state. Updates the position of the car in the environment.</li>
              <li>sense(car) ‚Äì returns the grid cell status as seen by the car. 1 if another car is present, 0 if the cell is free and -1 if the cell is not visible to your car.</li>
              <li>applyAction(s,a) ‚Äì returns the location where the car will move on applying action a in state s based on the inputs sensed by your car. Does not execute the action and does not update the state of the car in the environment.</li>
              <li>getAction(s1,s2) ‚Äì returns the action which takes a car from state s1 to state s2. The purpose of this function is to help you in retrieving the action sequence if you have a sequence of states visited after calling applyaction/act function. Please note that this function will not check for presence of other cars so a getAction will return forward if you pass it states (3,0) and (3,1) even if there is a car in (3,1). You need to use applyAction function to get the location where car will move on applying given action. You can also use the information about the presence/absence of other cars from the sense method.</li>
              </ol>
              <br>
              <p>Searchutils class functions ‚Äì Searchutils class contains utility functions for the search algorithm can be accessed by calling self.searchutil.<functionname></p><br>
              <ol>
              <li>retrieveActionSequenceFromState(s) ‚Äì retrieve the sequence of actions taken to reach the give state s. The action sequence is updated each time applyAction is called on env.</li>
              <li>isPresentStateInList(state,searchlist) ‚Äì returns 1 if the state is present in searchlist</li>
              <li>isPresentStateInPriorityList(state,searchlist) ‚Äì returns 1 if the state is present in priority list searchlist.</li>
              <li>insertStateInPriorityQueue(searchList,state,distanceToGoal) ‚Äì insert state with cost distancetogoal in the searchList.</li>
              <li>checkAndUpdateStateInPriorityQueue(searchList,state,distanceToGoal): checks if the state is present in the searchList with a cost higher than distanceToGoal. If the existing cost is higher then state is reinserted with the cost distancetoGoal in the searchList.</li>
              </ol>
              </p>

          </div>
          <div class="general-info">
            <ul>
              <li>
              Created - <span>26 Dec 2021</span>
            </li>
            <li>View Github repository - <span><a href="https://github.com/TejodhayBonam/SelfDrivingCar" target="_blank">SelfDrivingCar</a></span></li>
            </ul>
          </div>
        </div>
      </div>
        <!--Portfolio item end-->

        <!--Portfolio item start-->
        <div class="portfolio-item">
          <div class="portfolio-item-thumbnail">
            <img src="img/portfolio/ds_salary.png" alt="portfolio item thumb">
          </div>
          <h3 class="portfolio-item-title">Data Science Salary Estimator</h3>
          <button type="button" class="btn view-project-btn">view project</button>
          <div class="portfolio-item-details">
            <div class="description">
              <p><b><h1 id="ds_salary_proj">ds_salary_proj</h1>
                <h1 id="data-science-salary-estimator-project-overview">Data Science Salary Estimator: Project Overview</h1>
                
                <li>Created a tool that estimates data science salaries (MAE ~ $ 11K) to help data scientists negotiate their income when they get a job.</li>
                <li>Scraped over 1000 job descriptions from glassdoor using python and selenium</li>
                <li>Engineered features from the text of each job description to quantify the value companies put on python, excel, aws, and spark. </li>
                <li>Optimized Linear, Lasso, and Random Forest Regressors using GridsearchCV to reach the best model. </li>
                <li>Built a client facing API using flask </li>
                
                <h2 id="code-and-resources-used">Code and Resources Used</h2>
                <p><strong>Python Version:</strong> 3.7<br><strong>Packages:</strong> pandas, numpy, sklearn, matplotlib, seaborn, selenium, flask, json, pickle<br><strong>For Web Framework Requirements:</strong>  <code>pip install -r requirements.txt</code><br><strong>Scraper Github:</strong> <a href="https://github.com/arapfaik/scraping-glassdoor-selenium" target="_blank">https://github.com/arapfaik/scraping-glassdoor-selenium</a><br><strong>Scraper Article:</strong> <a href="https://towardsdatascience.com/selenium-tutorial-scraping-glassdoor-com-in-10-minutes-3d0915c6d905" target="_blank">https://towardsdatascience.com/selenium-tutorial-scraping-glassdoor-com-in-10-minutes-3d0915c6d905</a><br><strong>Flask Productionization:</strong> <a href="https://towardsdatascience.com/productionize-a-machine-learning-model-with-flask-and-heroku-8201260503d2" target="_blank">https://towardsdatascience.com/productionize-a-machine-learning-model-with-flask-and-heroku-8201260503d2</a></p>
                <h2 id="web-scraping">Web Scraping</h2>
                <p>Tweaked the web scraper github repo (above) to scrape 1000 job postings from glassdoor.com. With each job, we got the following:</p>
                
                <li>Job title</li>
                <li>Salary Estimate</li>
                <li>Job Description</li>
                <li>Rating</li>
                <li>Company </li>
                <li>Location</li>
                <li>Company Headquarters </li>
                <li>Company Size</li>
                <li>Company Founded Date</li>
                <li>Type of Ownership </li>
                <li>Industry</li>
                <li>Sector</li>
                <li>Revenue</li>
                <li>Competitors </li>
                
                <h2 id="data-cleaning">Data Cleaning</h2>
                <p>After scraping the data, I needed to clean it up so that it was usable for our model. I made the following changes and created the following variables:</p>
                
                <li>Parsed numeric data out of salary </li>
                <li>Made columns for employer provided salary and hourly wages </li>
                <li>Removed rows without salary </li>
                <li>Parsed rating out of company text </li>
                <li>Made a new column for company state </li>
                <li>Added a column for if the job was at the company‚Äôs headquarters </li>
                <li>Transformed founded date into age of company </li>
                <li>Made columns for if different skills were listed in the job description:<br>
                1. Python <br>
                2. R  <br>
                3. Excel<br>
                4. AWS<br>
                5. Spark<br>
                
                </li>
                <li>Column for simplified job title and Seniority </li>
                <li>Column for description length </li>
                
                <h2 id="eda">EDA</h2>
                <p>I looked at the distributions of the data and the value counts for the various categorical variables. Below are a few highlights from the pivot tables. </p>
                <p><img src="img/portfolio/salary_by_job_title.png" alt="alt text" title="Salary by Position">
                <img src="img/portfolio/ds_salary.png" alt="alt text" title="Job Opportunities by State">
                <img src="img/portfolio/correlation_visual.png" alt="alt text" title="Correlations"></p>
                <h2 id="model-building">Model Building</h2>
                <p>First, I transformed the categorical variables into dummy variables. I also split the data into train and tests sets with a test size of 20%.   </p>
                <br>
                <p>I tried three different models and evaluated them using Mean Absolute Error. I chose MAE because it is relatively easy to interpret and outliers aren‚Äôt particularly bad in for this type of model.   </p>
                <br>
                <p>I tried three different models:</p>
                <br>
                <li><strong>Multiple Linear Regression</strong> ‚Äì Baseline for the model</li>
                <li><strong>Lasso Regression</strong> ‚Äì Because of the sparse data from the many categorical variables, I thought a normalized regression like lasso would be effective.</li>
                <li><strong>Random Forest</strong> ‚Äì Again, with the sparsity associated with the data, I thought that this would be a good fit. </li>
                
                <h2 id="model-performance">Model performance</h2>
                <p>The Random Forest model far outperformed the other approaches on the test and validation sets. </p>
                
                <li><strong>Random Forest</strong> : MAE = 11.22</li>
                <li><strong>Linear Regression</strong>: MAE = 18.86</li>
                <li><strong>Ridge Regression</strong>: MAE = 19.67</li>
                
                <h2 id="productionization">Productionization</h2>
                <p>In this step, I built a flask API endpoint that was hosted on a local webserver by following along with the TDS tutorial in the reference section above. The API endpoint takes in a request with a list of values from a job listing and returns an estimated salary. </p>
                </p>

            </div>
            <div class="general-info">
              <ul>
                <li>
                Created - <span>22 Dec 2021</span>
              </li>
              <li>View Github repository - <span><a href="https://github.com/TejodhayBonam/ds_salary_proj" target="_blank">Data Science Salary Estimator</a></span></li>
              </ul>
            </div>
          </div>
        </div>
          <!--Portfolio item end-->

          <!--Portfolio item start-->
      <div class="portfolio-item">
        <div class="portfolio-item-thumbnail">
          <img src="img/portfolio/img_stitch.jpg" alt="portfolio item thumb">
        </div>
        <h3 class="portfolio-item-title">Multiple Image stitching in Python</h3>
        <button type="button" class="btn view-project-btn">view project</button>
        <div class="portfolio-item-details">
          <div class="description">
            <p><h1 id="multiple-image-stitching-in-python">Multiple Image stitching in Python</h1>
              <p>This repository contains an implementation of multiple image stitching. </p>
              <h3 id="requirements-">Requirements :</h3>
              <ul>
              <li>Python 2.7</li>
              <li>Numpy &gt;= 1.8 </li>
              <li>OpenCV 3.1.0 </li>
              </ul>
              <h3 id="project-structure-">Project Structure :</h3>
              <pre><code>    |<span class="hljs-string">_ code -</span>|
                  |<span class="hljs-string">         </span>|<span class="hljs-string">-- pano.py
                  </span>|<span class="hljs-string">         </span>|<span class="hljs-string">-- txtlists-</span>|
                  |<span class="hljs-string">                       </span>|<span class="hljs-string">--files1.txt .... 
                  </span>|<span class="hljs-string">    
                  </span>|<span class="hljs-string">_ images - </span>|
                  |<span class="hljs-string">            </span>|<span class="hljs-string">- img1.jpg
                  </span>|<span class="hljs-string">            </span>|<span class="hljs-string">- abc.jpg 
                  </span>|<span class="hljs-string">            .... and so on ... </span>
              </code></pre><p>Demo txtfile : 
              files2.txt :</p>
              <pre><code>    ../../images/<span class="hljs-number">1.</span>jpg
                  ../../images/<span class="hljs-number">2.</span>jpg
                  ../../images/<span class="hljs-number">3.</span>jpg
                  ../../images/<span class="hljs-number">4.</span>jpg
              </code></pre><h3 id="to-run-">To run :</h3>
              <pre><code>`python pano.py &lt;txtlists/filename_.txt&gt;`
              </code></pre><h2 id="outputs-">Outputs !!</h2>
              <center>
              <img src="img/portfolio/lunchroom.jpg"><br>
              <caption>Stitching with Lunchroom example</caption>
              <br><br>
              <img src="img/portfolio/home.jpg"><br>
              <caption>Stitching with home example</caption>
              <br><br>
              <img src="img/portfolio/building.jpg"><br>
              <caption>Stitching with building example</caption>
              <br><br>
              <img src="img/portfolio/hill.jpg"><br>
              <caption>Stitching using Hill example</caption>
              <br><br>
              <img src="img/portfolio/room.jpg"><br>
              <caption>Stitching using room example</caption>
              <br>
              </center>
              
              <h3 id="other-websources-for-images-">Other WebSources for Images :</h3>
              <p>Base paper for panorama using scale invariant features :</p>
              <p>[1] &quot;Automatic Panoramic Image Stitching using Invariant Features&quot;, Download.springer.com, 2016. [Online]. Available: matthewalunbrown.com/papers/ijcv2007.pdf</p>
              <p>Test images taken from :</p>
              <p>[2]&quot;PASSTA Datasets&quot;, Cvl.isy.liu.se, 2016. [Online]. Available: <a href="http://www.cvl.isy.liu.se/en/research/datasets/passta/" target="_blank">http://www.cvl.isy.liu.se/en/research/datasets/passta/</a>.</p>
              <p>[3] &quot;OpenCV Stitching example (Stitcher class, Panorama)&quot;, Study.marearts.com, 2013. [Online]. Available: <a href="http://study.marearts.com/2013/11/opencv-stitching-example-stitcher-class.html" target="_blank">http://study.marearts.com/2013/11/opencv-stitching-example-stitcher-class.html</a>.</p>
              <p>[4] &quot;Github daeyun Image-Stitching Test Images&quot;, 2016. [Online]. Available: <a href="https://github.com/daeyun/Image-Stitching/tree/master/img/hill" target="_blank">https://github.com/daeyun/Image-Stitching/tree/master/img/hill</a>. </p>
              <p>[5] &quot;Github tsherlock Test Images&quot;, 2016. [Online]. Available: .  <a href="https://github.com/tsherlock/panorama/" target="_blank">https://github.com/tsherlock/panorama/</a></p>
              </p>

          </div>
          <div class="general-info">
            <ul>
              <li>
              Created - <span>22 Dec 2021</span>
            </li>
            <li>View Github repository - <span><a href="https://github.com/TejodhayBonam/Python-Multiple-Image-Stitching" target="_blank">Multiple Image stitching in Python</a></span></li>
            </ul>
          </div>
        </div>
      </div>
        <!--Portfolio item end-->
          
        </div>
      </div>
    </section>
  <!--Portfolio Section End-->

    <!--Contact section Start-->
    <section class="contact-section sec-padding" id="contact">
      <div class="container">
        <div class="row">
          <div class="section-title">
            <h2>Contact me</h2>
          </div>
        </div>
        <div class="row">
          <div class="contact-form">
            <form>
              <div class="row">
                <div class="input-group">
                  <input type="text" placeholder="Name" class="input-control" required>
                </div>
                <div class="input-group">
                  <input type="text" placeholder="Email" class="input-control" required>
                </div>
                <div class="input-group">
                  <input type="text" placeholder="Phone" class="input-control" required>
                </div>
                <div class="input-group">
                  <input type="text" placeholder="Subject" class="input-control" required>
                </div>
                <div class="input-group">
                  <textarea placeholder="Message" class="input-control" required></textarea>
                </div>
                <div class="submit-btn">
                  <button type="submit" class="btn">send message</button>
                </div>
              </div>
            </form>
          </div>
          <div class="contact-info">
            <div class="contact-info-item">
              <h3>Email</h3>
              <p>example@gmail.com</p>
            </div>
            <div class="contact-info-item">
              <h3>Phone</h3>
              <p>91 98 **** ****</p>
            </div>
            <div class="contact-info-item">
              <h3>Follow Me</h3>
              <div class="social-links">
                <a href="#" target="_blank"><i class="fab fa-facebook-f"></i></a>
                <a href="#" target="_blank"><i class="fab fa-twitter"></i></a>
                <a href="#" target="_blank"><i class="fab fa-instagram"></i></a>
                <a href="#" target="_blank"><i class="fab fa-youtube"></i></a>
                <a href="https://www.linkedin.com/in/tejodhay-bonam-66b3661b0/" target="_blank"><i class="fab fa-linkedin"></i></a>
                <a href="https://github.com/TejodhayBonam" target="_blank"><i class="fab fa-github"></i></a>
              </div>
            </div>
          </div>
        </div>
      </div>
    </section>
    <!--Contact section End-->
  </div>
  <!--Main End-->

  <!--Portfolio Items Details Popup Start-->
<div class="portfolio-popup">
<div class="pp-inner">
  <div class="pp-content">
    <div class="pp-header">
      <button type="button" class="btn pp-close"><i class="fas fa-times"></i></button>
      <div class="pp-thumbnail">
        <img src="img/portfolio/3.jpg" alt="pp-thumbnail">
      </div>
      <h3></h3>
    </div>
    <div class="pp-body"> 
    </div>
  </div>
</div>
</div>
  <!--Portfolio Items Details Popup End-->
<script src="js/script.js"></script>
</body>
</html>
